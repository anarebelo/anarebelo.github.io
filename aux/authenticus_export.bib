
@inproceedings{Authenticus:P-00R-P8G,
Author={Pedro M Ferreira and Diogo Pernes and Ana Rebelo and Jaime S Cardoso},
Title={{Learning Signer-Invariant Representations with Adversarial Training}},
Year={{2020}},
Series={{Proceedings of SPIE}},
Editor={Osten, W and Nikolaev, D and Zhou, J},
Booktitle={{TWELFTH INTERNATIONAL CONFERENCE ON MACHINE VISION (ICMV 2019)}},
Abstract={{Sign Language Recognition (SLR) has become an appealing topic in modern societies because such technology can ideally be used to bridge the gap between deaf and hearing people. Although important steps have been made towards the development of real-world SLR systems, signer-independent SLR is still one of the bottleneck problems of this research field. In this regard, we propose a deep neural network along with an adversarial training objective, specifically designed to address the signer-independent problem. Concretely speaking, the proposed model consists of an encoder, mapping from input images to latent representations, and two classifiers operating on these underlying representations: (i) the signclassifier, for predicting the class/sign labels, and (ii) the signer-classifier, for predicting their signer identities. During the learning stage, the encoder is simultaneously trained to help the sign-classifier as much as possible while trying to fool the signer-classifier. This adversarial training procedure allows learning signer-invariant latent representations that are in fact highly discriminative for sign recognition. Experimental results demonstrate the effectiveness of the proposed model and its capability of dealing with the large inter-signer variations.}},
Publisher={{SPIE-INT SOC OPTICAL ENGINEERING}},
Address1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA}},
Volume={{11433}},
Key={{DOI:10.1117/12.2559534}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-00R-F8M,
Author={Ferreira, PM and Sequeira, AF and Pernes, D and Rebelo, A and Cardoso, JS},
Title={{Adversarial learning for a robust iris presentation attack detection method against unseen attack presentations}},
Year={{2019}},
Editor={Bromme A.busch C.dantcheva A.rathgeb C.uhl A.},
Booktitle={{2019 International Conference of the Biometrics Special Interest Group, BIOSIG 2019 - Proceedings}},
Abstract={{Despite the high performance of current presentation attack detection (PAD) methods, the robustness to unseen attacks is still an under addressed challenge. This work approaches the problem by enforcing the learning of the bona fide presentations while making the model less dependent on the presentation attack instrument species (PAIS). The proposed model comprises an encoder, mapping from input features to latent representations, and two classifiers operating on these underlying representations: (i) the task-classifier, for predicting the class labels (as bona fide or attack); and (ii) the species-classifier, for predicting the PAIS. In the learning stage, the encoder is trained to help the task-classifier while trying to fool the species-classifier. Plus, an additional training objective enforcing the similarity of the latent distributions of different species is added leading to a 'PAI-species'-independent model. The experimental results demonstrated that the proposed regularisation strategies equipped the neural network with increased PAD robustness. The adversarial model obtained better loss and accuracy as well as improved error rates in the detection of attack and bona fide presentations. © 2019 Gesellschaft fuer Informatik.}},
Publisher={{Institute of Electrical and Electronics Engineers Inc.}},
Type={Proceedings Paper},
Note={Citations: scopus}
}       

﻿
@inproceedings{Authenticus:P-00R-C1N,
Author={Sousa, J and Rebelo, A and Cardoso, JS},
Title={{Automation of Waste Sorting with Deep Learning}},
Year={{2019}},
Editor={Wachs-lopes G.a.},
Booktitle={{Proceedings - 15th Workshop of Computer Vision, WVC 2019}},
Abstract={{The importance of recycling is well known, either for environmental or economic reasons, it is impossible to escape it and the industry demands efficiency. Manual labour and traditional industrial sorting techniques are not capable of keeping up with the objectives demanded by the international community. Solutions based in computer vision techniques have the potential automate part of the waste handling tasks. In this paper, we propose a hierarchical deep learning approach for waste detection and classification in food trays. The proposed two-step approach retains the advantages of recent object detectors (as Faster R-CNN) and allows the classification task to be supported in higher resolution bounding boxes. Additionally, we also collect, annotate and make available to the scientific community a new dataset, named Labeled Waste in the Wild, for research and benchmark purposes. In the experimental comparison with standard deep learning approaches, the proposed hierarchical model shows better detection and classification performance. © 2019 IEEE.}},
Publisher={{Institute of Electrical and Electronics Engineers Inc.}},
Pages={{43-48}},
Key={{DOI:10.1109/wvc.2019.8876924}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus}
}       

@article{Authenticus:P-00R-HFD,
Author={Pedro M Ferreira and Diogo Pernes and Ana Rebelo and Jaime S Cardoso},
Title={{DeSIRe: Deep Signer-Invariant Representations for Sign Language Recognition}},
Year={{2019}},
Journal={{IEEE Transactions on Systems, Man, and Cybernetics: Systems}},
Publisher={{Institute of Electrical and Electronics Engineers (IEEE)}},
Pages={{1-16}},
Key={{DOI:10.1109/tsmc.2019.2957347}}, 
Type={Article},
Note={Citations: crossref}
}       

@article{Authenticus:P-00P-M59,
Author={Pedro M Ferreira and Jaime S Cardoso and Ana Rebelo},
Title={{On the role of multimodal learning in the recognition of sign language}},
Year={{2019}},
Journal={{MULTIMEDIA TOOLS AND APPLICATIONS}},
Abstract={{Sign Language Recognition (SLR) has become one of the most important research areas in the field of human computer interaction. SLR systems are meant to automatically translate sign language into text or speech, in order to reduce the communicational gap between deaf and hearing people. The aim of this paper is to exploit multimodal learning techniques for an accurate SLR, making use of data provided by Kinect and Leap Motion. In this regard, single-modality approaches as well as different multimodal methods, mainly based on convolutional neural networks, are proposed. Our main contribution is a novel multimodal end-to-end neural network that explicitly models private feature representations that are specific to each modality and shared feature representations that are similar between modalities. By imposing such regularization in the learning process, the underlying idea is to increase the discriminative ability of the learned features and, hence, improve the generalization capability of the model. Experimental results demonstrate that multimodal learning yields an overall improvement in the sign recognition performance. In particular, the novel neural network architecture outperforms the current state-of-the-art methods for the SLR task.}},
Publisher={{SPRINGER}},
AddressVAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Volume={{78}},
Number={{8}}, 
Pages={{10035-10056}},
Key={{DOI:10.1007/s11042-018-6565-5}}, 
Type={Article},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-00Q-8NE,
Author={Ana Rebelo and Tiago Oliveira and Manuel Eduardo Correia and Jaime S Cardoso},
Title={{Are Deep Learning Methods Ready for Prime Time in Fingerprints Minutiae Extraction?}},
Year={{2018}},
Series={{Lecture Notes in Computer Science}},
Editor={Rubén Vera-rodríguez and Julian Fiérrez and Aythami Morales},
Booktitle={{Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications - 23rd Iberoamerican Congress, CIARP 2018, Madrid, Spain, November 19-22, 2018, Proceedings}},
Abstract={{Currently the breakthroughs in most computer vision problems have been achieved by applying deep learning methods. The traditional methodologies that used to successfully discriminate the data features appear to be overwhelmed by the capabilities of learning of the deep network architectures. Nevertheless, many recent works choose to integrate the old handcrafted features into the deep convolutional networks to increase even more their impressive performance. In fingerprint recognition, the minutiae are specific points used to identify individuals and their extraction is a crucial module in a fingerprint recognition system. This can only be emphasized by the fact that the US Federal Bureau of Investigation (FBI) sets as a threshold for a positive identification a number of 8 common minutiae. Deep neural networks have been used to learn possible representations of fingerprint minutiae but, however surprisingly, in this paper it is shown that for now the best choice for an automatic minutiae extraction system is still the traditional road map. A comparison study was conducted with state-of-the-art methods and the best results were achieved by handcraft features. © Springer Nature Switzerland AG 2019.}},
Publisher={{Springer}},
AddressCham}},
Volume={{11401}},
Pages={{628-636}},
Key={{DOI:10.1007/978-3-030-13469-3_73}}, 
Type={Proceedings Paper},
Note={Citations: crossref, dblp, scopus}
}       

@article{Authenticus:P-00P-T6W,
Author={Pedro M Ferreira and Filipe Marques and Jaime S Cardoso and Ana Rebelo},
Title={{Physiological Inspired Deep Neural Networks for Emotion Recognition}},
Year={{2018}},
Journal={{IEEE ACCESS}},
Abstract={{Facial expression recognition (FER) is currently one of the most active research topics due to its wide range of applications in the human-computer interaction field. An important part of the recent success of automatic FER was achieved thanks to the emergence of deep learning approaches. However, training deep networks for FER is still a very challenging task, since most of the available FER data sets are relatively small. Although transfer learning can partially alleviate the issue, the performance of deep models is still below of its full potential as deep features may contain redundant information from the pre-trained domain. Instead, we propose a novel end-to-end neural network architecture along with a well-designed loss function based on the strong prior knowledge that facial expressions are the result of the motions of some facial muscles and components. The loss function is defined to regularize the entire learning process so that the proposed neural network is able to explicitly learn expression-specific features. Experimental results demonstrate the effectiveness of the proposed model in both lab-controlled and wild environments. In particular, the proposed neural network provides quite promising results, outperforming in most cases the current state-of-the-art methods.}},
Publisher={{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Volume={{6}},
Pages={{53930-53943}},
Key={{DOI:10.1109/access.2018.2870063}}, 
Type={Article},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-00R-R6N,
Author={Ferreira, PM and Sequeira, AF and Cardoso, JS and Rebelo, A},
Title={{Robust Clustering-based Segmentation Methods for Fingerprint Recognition}},
Year={{2018}},
Editor={Bromme A.uhl A.busch C.rathgeb C.dantcheva A.},
Booktitle={{2018 International Conference of the Biometrics Special Interest Group, BIOSIG 2018}},
Abstract={{Fingerprint recognition has been widely studied for more than 45 years and yet it remains an intriguing pattern recognition problem. This paper focuses on the foreground mask estimation which is crucial for the accuracy of a fingerprint recognition system. The method consists of a robust cluster-based fingerprint segmentation framework incorporating an additional step to deal with pixels that were rejected as foreground in a decision considered not reliable enough. These rejected pixels are then further analysed for a more accurate classification. The procedure falls in the paradigm of classification with reject option- a viable option in several real world applications of machine learning and pattern recognition, where the cost of misclassifying observations is high. The present work expands a previous method based on the fuzzy C-means clustering with two variations regarding: i) the filters used; and ii) the clustering method for pixel classification as foreground/background. Experimental results demonstrate improved results on FVC datasets comparing with state-of-the-art methods even including methodologies based on deep learning architectures. © 2018 Gesellschaft fuer Informatik.}},
Publisher={{Institute of Electrical and Electronics Engineers Inc.}},
Key={{DOI:10.23919/biosig.2018.8553022}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus}
}       

﻿
@inproceedings{Authenticus:P-00N-B26,
Author={Pedro M Ferreira and Jaime S Cardoso and Ana Rebelo},
Title={{Multimodal Learning for Sign Language Recognition}},
Year={{2017}},
Series={{Lecture Notes in Computer Science}},
Editor={Alexandre, La and Sanchez, Js and Rodrigues, Jmf},
Booktitle={{PATTERN RECOGNITION AND IMAGE ANALYSIS (IBPRIA 2017)}},
Abstract={{Sign Language Recognition (SLR) has becoming one of the most important research areas in the field of human computer interaction. SLR systems are meant to automatically translate sign language into text or speech, in order to reduce the communicational gap between deaf and hearing people. The aim of this paper is to exploit multimodal learning techniques for an accurate SLR, making use of data provided by Kinect and Leap Motion. In this regard, single-modality approaches as well as different multimodal methods, mainly based on convolutional neural networks, are proposed. Experimental results demonstrate that multimodal learning yields an overall improvement in the sign recognition performance.}},
Publisher={{SPRINGER INTERNATIONAL PUBLISHING AG}},
AddressGEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Volume={{10255}},
Pages={{313-321}},
Key={{DOI:10.1007/978-3-319-58838-4_35}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

@article{Authenticus:P-00K-9SQ,
Author={Cuihong H Wen and Jing Zhang and Ana Rebelo and Fanyong Y Cheng},
Title={{A Directed Acyclic Graph-Large Margin Distribution Machine Model for Music Symbol Classification}},
Year={{2016}},
Editor={Ebrahimi, Mansour},
Journal={{PLOS ONE}},
Abstract={{Optical Music Recognition (OMR) has received increasing attention in recent years. In this paper, we propose a classifier based on a new method named Directed Acyclic Graph-Large margin Distribution Machine (DAG-LDM). The DAG-LDM is an improvement of the Large margin Distribution Machine (LDM), which is a binary classifier that optimizes the margin distribution by maximizing the margin mean and minimizing the margin variance simultaneously. We modify the LDM to the DAG-LDM to solve the multi-class music symbol classification problem. Tests are conducted on more than 10000 music symbol images, obtained from handwritten and printed images of music scores. The proposed method provides superior classification capability and achieves much higher classification accuracy than the state-of-the-art algorithms such as Support Vector Machines (SVMs) and Neural Networks (NNs).}},
Publisher={{PUBLIC LIBRARY SCIENCE}},
Address1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA}},
Volume={{11}},
Number={{3}}, 
Pages={{e0149688}},
Key={{DOI:10.1371/journal.pone.0149688}}, 
Type={Article},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-00G-EA9,
Author={Pedro M Ferreira and Ana F Sequeira and Ana Rebelo},
Title={{A Fuzzy C-Means Algorithm for Fingerprint Segmentation}},
Year={{2015}},
Series={{Lecture Notes in Computer Science}},
Editor={Paredes, R and Cardoso, Js and Pardo, Xm},
Booktitle={{PATTERN RECOGNITION AND IMAGE ANALYSIS (IBPRIA 2015)}},
Abstract={{Fingerprint segmentation is a crucial step of an automatic fingerprint identification system, since an accurate segmentation promote both the elimination of spurious minutiae close to the foreground boundaries and the reduction of the computation time of the following steps. In this paper, a new, and more robust fingerprint segmentation algorithm is proposed. The main novelty is the introduction of a more robust binarization process in the framework, mainly based on the fuzzy C-means clustering algorithm. Experimental results demonstrate significant benchmark progress on three existing FVC datasets.}},
Publisher={{SPRINGER-VERLAG BERLIN}},
AddressHEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Volume={{9117}},
Pages={{245-252}},
Key={{DOI:10.1007/978-3-319-19390-8_28}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

@article{Authenticus:P-00G-3T8,
Author={Cuihong H Wen and Ana Rebelo and Jing Zhang and Jaime Cardoso},
Title={{A new optical music recognition system based on combined neural network}},
Year={{2015}},
Journal={{PATTERN RECOGNITION LETTERS}},
Abstract={{Optical music recognition (OMR) is an important tool to recognize a scanned page of music sheet automatically, which has been applied to preserving music scores. In this paper, we propose a new OMR system to recognize the music symbols without segmentation. We present a new classifier named combined neural network (CNN) that offers superior classification capability. We conduct tests on fifteen pages of music sheets, which are real and scanned images. The tests show that the proposed method constitutes an interesting contribution to OMR.}},
Publisher={{ELSEVIER SCIENCE BV}},
AddressPO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Volume={{58}},
Pages={{1-7}},
Key={{DOI:10.1016/j.patrec.2015.02.002}}, 
Type={Article},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-00K-2SA,
Author={Cuihong H Wen and Ana Rebelo and Jing Zhang and Jaime Cardoso},
Title={{Classification of Optical Music Symbols based on Combined Neural Network}},
Year={{2014}},
Booktitle={{2014 INTERNATIONAL CONFERENCE ON MECHATRONICS AND CONTROL (ICMC)}},
Abstract={{In this paper, a new method for music symbol classification named Combined Neural Network (CNN) is proposed. Tests are conducted on more than 9000 music symbols from both real and scanned music sheets, which show that the proposed technique offers superior classification capability. At the same time, the performance of the new network is compared with the single Neural Network (NN) classifier using the same music scores. The average classification accuracy increased more than ten percent, reaching 98.82%.}},
Publisher={{IEEE}},
Address345 E 47TH ST, NEW YORK, NY 10017 USA}},
Pages={{419-423}},
Key={{DOI:10.1109/icmc.2014.7231590}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-009-VBM,
Author={Ana F Sequeira and Joao C Monteiro and Ana Rebelo and Helder P Oliveira},
Title={{MobBIO: A Multimodal Database Captured with a Portable Handheld Device}},
Year={{2014}},
Series={{VISAPP (3)}},
Editor={Battiato, S and Braz, J},
Booktitle={{PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3}},
Abstract={{Biometrics represents a return to a natural way of identification: testing someone by what (s) he is, instead of relying on something (s) he owns or knows seems likely to be the way forward. Biometric systems that include multiple sources of information are known as multimodal. Such systems are generally regarded as an alternative to fight a variety of problems all unimodal systems stumble upon. One of the main challenges found in the development of biometric recognition systems is the shortage of publicly available databases acquired under real unconstrained working conditions. Motivated by such need the MobBIO database was created using an Asus EeePad Transformer tablet, with mobile biometric systems in mind. The proposed database is composed by three modalities: iris, face and voice.}},
Publisher={{IEEE}},
Address345 E 47TH ST, NEW YORK, NY 10017 USA}},
Volume={{3}},
Pages={{133-139}},
Type={Proceedings Paper},
Note={Citations: dblp, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-008-E95,
Author={Ana Rebelo and Andre R S Marcal and Jaime S Cardoso},
Title={{Global Constraints for Syntactic Consistency in OMR: An Ongoing Approach}},
Year={{2013}},
Series={{Lecture Notes in Computer Science}},
Editor={Kamel, M and Campilho, A},
Booktitle={{IMAGE ANALYSIS AND RECOGNITION}},
Abstract={{Optical Music Recognition (OMR) systems are an indispensable tool to transform the paper-based music scores and manuscripts into a machine-readable symbolic format. A system like this potentiates search, retrieval and analysis. One of the problematic stages is the musical symbols detection where operations to localize and to isolate musical objects are developed. The complexity is caused by printing and digitalization, as well as the paper degradation over time. Distortions inherent in staff lines, broken, connected and overlapping symbols, differences in sizes and shapes, noise, and zones of high density of symbols is even worst when we are dealing with handwritten music scores. In this paper the exploration of an optimization approach to support semantic and syntactic consistency after the music symbols extraction phase is proposed. The inclusion of this ongoing technique can lead to better results and encourage further experiences in the field of handwritten music scores recognition.}},
Publisher={{SPRINGER-VERLAG BERLIN}},
AddressHEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Volume={{7950}},
Pages={{734-741}},
Key={{DOI:10.1007/978-3-642-39094-4_84}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-008-J7C,
Author={Ana Rebelo and Jaime S Cardoso},
Title={{Staff line Detection and Removal in the Grayscale Domain}},
Year={{2013}},
Series={{Proceedings of the International Conference on Document Analysis and Recognition}},
Booktitle={{2013 12TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR)}},
Abstract={{The detection of staff lines is the first step of most Optical Music Recognition (OMR) systems. Its great significance derives from the ease with which we can then proceed with the extraction of musical symbols. All OMR tasks are usually achieved using binary images by setting thresholds that can be local or global. These techniques however, may remove relevant information of the music sheet and introduce artifacts which will degrade results in the later stages of the process. It arises therefore a need to create a method that reduces the loss of information due to the binarization. The baseline for the methodology proposed in this paper follows the shortest path algorithm proposed in [1]. The concept of strong staff pixels (SSP's), which is a set of pixels with a high probability of belonging to a staff line, is proposed to guide the cost function. The SSP allows to overcome the results of the binary based detection and to generalize the binary framework to grayscale music scores. The proposed methodology achieves good results.}},
Publisher={{IEEE}},
Address345 E 47TH ST, NEW YORK, NY 10017 USA}},
Pages={{57-61}},
Key={{DOI:10.1109/icdar.2013.20}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

@article{Authenticus:P-00H-5KZ,
Author={Rebelo, A and Fujinaga, I and Paszkiewicz, F and Marcal, ARS and Guedes, C and Cardoso, JS},
Title={{Optical music recognition: state-of-the-art and open issues}},
Year={{2012}},
Journal={{International Journal of Multimedia Information Retrieval}},
Abstract={{For centuries, music has been shared and remembered by two traditions: aural transmission and in the form of written documents normally called musical scores. Many of these scores exist in the form of unpublished manuscripts and hence they are in danger of being lost through the normal ravages of time. To preserve the music some form of typesetting or, ideally, a computer system that can automatically decode the symbolic images and create new scores is required. Programs analogous to optical character recognition systems called optical music recognition (OMR) systems have been under intensive development for many years. However, the results to date are far from ideal. Each of the proposed methods emphasizes different properties and therefore makes it difficult to effectively evaluate its competitive advantages. This article provides an overview of the literature concerning the automatic analysis of images of printed and handwritten musical scores. For self-containment and for the benefit of the reader, an introduction to OMR processing systems precedes the literature overview. The following study presents a reference scheme for any researcher wanting to compare new OMR algorithms against well-known ones. © 2012, Springer-Verlag London Limited.}},
Publisher={{Springer London}},
Volume={{1}},
Number={{3}}, 
Pages={{173-190}},
Key={{DOI:10.1007/s13735-012-0004-6}}, 
Type={Article},
Note={Citations: crossref, scopus}
}       

﻿
@inproceedings{Authenticus:P-008-2WP,
Author={Rebelo, A and Tkaczuk, J and Sousa, R and Cardoso, JS},
Title={{Metric learning for music symbol recognition}},
Year={{2011}},
Booktitle={{Proceedings - 10th International Conference on Machine Learning and Applications, ICMLA 2011}},
Abstract={{Although Optical Music Recognition (OMR) has been the focus of much research for decades, the processing of handwritten musical scores is not yet satisfactory. The efforts made to find robust symbol representations and learning methodologies have not found a similar quality in the learning of the dissimilarity concept. Simple Euclidean distances are often used to measure dissimilarity between different examples. However, such distances do not necessarily yield the best performance. In this paper, we propose to learn the best distance for the k-nearest neighbor (k-NN) classifier. The distance concept will be tuned both for the application domain and the adopted representation for the music symbols. The performance of the method is compared with the support vector machine (SVM) classifier using both real and synthetic music scores. The synthetic database includes four types of deformations inducing variability in the printed musical symbols which exist in handwritten music sheets. The work presented here can open new research paths towards a novel automatic musical symbols recognition module for handwritten scores. © 2011 IEEE.}},
Publisher={{Institute of Electrical & Electronics Engineers (IEEE)}},
Volume={{2}},
Pages={{106-111}},
Key={{DOI:10.1109/icmla.2011.94}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus}
}       

﻿
@inproceedings{Authenticus:P-002-WW5,
Author={Telmo Pinto and Ana Rebelo and Gilson Giraldi and Jaime S Cardoso},
Title={{Music Score Binarization Based on Domain Knowledge}},
Year={{2011}},
Series={{Lecture Notes in Computer Science}},
Editor={Vitria, J and Sanches, Jm and Hernandez, M},
Booktitle={{PATTERN RECOGNITION AND IMAGE ANALYSIS: 5TH IBERIAN CONFERENCE, IBPRIA 2011}},
Abstract={{Image binarization is a common operation in the preprocessing stage in most Optical Music Recognition (OMR) systems. The choice of an appropriate binarization method for handwritten music scores is a difficult problem. Several works have already evaluated the performance of existing binarization processes in diverse applications. However, no goal-directed studies for music sheets documents were carried out. This paper presents a novel binarization method based in the content knowledge of the image. The method only needs the estimation of the staffline thickness and the vertical distance between two stafflines. This information is extracted directly from the gray level music score. The proposed binarization procedure is experimentally compared with several state of the art methods.}},
Publisher={{SPRINGER-VERLAG BERLIN}},
AddressHEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Volume={{6669}},
Pages={{700-708}},
Key={{DOI:10.1007/978-3-642-21257-4_87}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

@article{Authenticus:P-003-8Q7,
Author={Rebelo, A and Capela, G and Jaime S Cardoso},
Title={{Optical recognition of music symbols}},
Year={{2010}},
Journal={{INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION}},
Abstract={{Many musical works produced in the past are still currently available only as original manuscripts or as photocopies. The preservation of these works requires their digitalization and transformation into a machine-readable format. However, and despite the many research activities on optical music recognition (OMR), the results for handwritten musical scores are far from ideal. Each of the proposed methods lays the emphasis on different properties and therefore makes it difficult to evaluate the efficiency of a proposed method. We present in this article a comparative study of several recognition algorithms of music symbols. After a review of the most common procedures used in this context, their respective performances are compared using both real and synthetic scores. The database of scores was augmented with replicas of the existing patterns, transformed according to an elastic deformation technique. Such transformations aim to introduce invariances in the prediction with respect to the known variability in the symbols, particularly relevant on handwritten works. The following study and the adopted databases can constitute a reference scheme for any researcher who wants to confront a new OMR algorithm face to well-known ones.}},
Publisher={{SPRINGER HEIDELBERG}},
AddressTIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY}},
Volume={{13}},
Number={{1}}, 
Pages={{19-31}},
Key={{DOI:10.1007/s10032-009-0100-1}}, 
Type={Article},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-007-W5M,
Author={Cardoso, JS and Rebelo, A},
Title={{Robust staffline thickness and distance estimation in binary and gray-level music scores}},
Year={{2010}},
Booktitle={{Proceedings - International Conference on Pattern Recognition}},
Abstract={{The optical recognition of handwritten musical scores by computers remains far from ideal. Most OMR algorithms rely on an estimation of the staffline thickness and the vertical line distance within the same staff. Subsequent operation can use these values as references, dismissing the need for some predetermined threshold values. In this work we improve on previous conventional estimates for these two reference lengths. We start by proposing a new method for binarized music scores and then extend the approach for gray-level music scores. An experimental study with 50 images is used to assess the interest of the novel method. © 2010 IEEE.}},
Publisher={{Institute of Electrical & Electronics Engineers (IEEE)}},
Pages={{1856-1859}},
Key={{DOI:10.1109/icpr.2010.458}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus}
}       

@article{Authenticus:P-003-JM6,
Author={Jaime dos Santos Cardoso and Artur Capela and Ana Rebelo and Carlos Guedes and Joaquim Pinto da Costa},
Title={{Staff Detection with Stable Paths}},
Year={{2009}},
Journal={{IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE}},
Abstract={{The preservation of musical works produced in the past requires their digitalization and transformation into a machine-readable format. The processing of handwritten musical scores by computers remains far from ideal. One of the fundamental stages to carry out this task is the staff line detection. We investigate a general-purpose, knowledge-free method for the automatic detection of music staff lines based on a stable path approach. Lines affected by curvature, discontinuities, and inclination are robustly detected. Experimental results show that the proposed technique consistently outperforms well-established algorithms.}},
Publisher={{IEEE COMPUTER SOC}},
Address10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Volume={{31}},
Number={{6}}, 
Pages={{1134-1139}},
Key={{DOI:10.1109/tpami.2009.34}}, 
Type={Article},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-004-54Y,
Author={Jaime S Cardoso and Artur Capela and Ana Rebelo and Carlos Guedes},
Title={{A CONNECTED PATH APPROACH FOR STAFF DETECTION ON A MUSIC SCORE}},
Year={{2008}},
Series={{IEEE International Conference on Image Processing (ICIP)}},
Booktitle={{2008 15TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-5}},
Abstract={{The preservation of many music works produced in the past entails their digitalization and consequent accessibility in an easy-to-manage digital format. Carrying this task manually is very time consuming and error prone. While optical music recognition systems usually perform well on printed scores, the processing of handwritten musical scores by computers remain far from ideal. One of the fundamental stages to carry out this task is the staff line detection. In this paper a new method for the automatic detection of music staff lines based on a connected path approach is presented. Lines affected by curvature, discontinuities, and inclination are robustly detected. Experimental results show that the proposed technique consistently outperforms well-established algorithms.}},
Publisher={{IEEE}},
Address345 E 47TH ST, NEW YORK, NY 10017 USA}},
Pages={{1005-1008}},
Key={{DOI:10.1109/icip.2008.4711927}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-00A-84H,
Author={Capela, A and Cardoso, JS and Rebelo, A and Guedes, C},
Title={{Integrated recognition systemfor music scores}},
Year={{2008}},
Booktitle={{International Computer Music Conference, ICMC 2008}},
Abstract={{Many music works produced in the last century still exist only as original manuscripts or as photocopies. Preserving them entails their digitalization and consequent accessibility in a digital format easy-to-manage which encourages browsing, retrieval, search and analysis while providing a generalized access to the digital material. The manual process to carry out this task is very time consuming and error prone. Automatic optical music recognition (OMR) has emerged as a partial solution to this problem. However, the full potential of this process only reveals itself when integrated in a system that provides seamless access to browsing, retrieval, search and analysis. We address this demand by proposing a modular, flexible and scalable framework that fully integrates the abovementioned functionalities. A web based system to carry out the automatic recognition process, allowing the creation and management of a music corpus, while providing generalized access to it, is a unique and innovative approach to the problem. A prototype has been implemented and is being used as a test platform for OMR algorithms.}},
Publisher={{International Computer Music Association}},
Type={Proceedings Paper},
Note={Citations: scopus}
}       

﻿
@inproceedings{Authenticus:P-004-4V7,
Author={Artur Capela and Ana Rebelo and Jaime S Cardoso and Carlos Guedes},
Title={{Staff line detection and removal with stable paths}},
Year={{2008}},
Editor={Assuncao, P and Faria, S},
Booktitle={{SIGMAP 2008: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS}},
Abstract={{Many music works produced in the past are currently available only as original manuscripts or as photocopies. Preserving them entails their digitalization and consequent accessibility in a machine-readable format, which encourages browsing, retrieval, search and analysis while providing a generalized access to the digital material. Carrying this task manually is very time consuming and error prone. While optical music recognition (OMR) systems usually perform well on printed scores, the processing of handwritten music by computers remains below the expectations. One of the fundamental stages to carry out this task is the detection and subsequent removal of staff lines. In this paper we integrate a general-purpose, knowledge-free method for the automatic detection of staff lines based on stable paths, into a recently developed staff line removal toolkit. Lines affected by curvature, discontinuities, and inclination are robustly detected. We have also developed a staff removal algorithm adapting an existing line removal approach to use the stable path algorithm at the detection stage, Experimental results show that the proposed technique outperforms well-established algorithms. The developed algorithm will now be integrated in a web based system providing seamless access to browsing, retrieval, search and analysis of submitted scores.}},
Publisher={{INSTICC-INST SYST TECHNOLOGIES INFORMATION CONTROL & COMMUNICATION}},
AddressAVENIDA D MANUEL L, 27A 2 ESQUERDO, SETUBAL, 2910-595, PORTUGAL}},
Pages={{263-270}},
Type={Proceedings Paper},
Note={Citations: scopus, wos}
}       

﻿
@inproceedings{Authenticus:P-004-CKG,
Author={Ana Rebelo and Artur Capela and Joaquim F Pinto da Costa and Carlos Guedes and Eurico Carrapatoso and Jaime S Cardoso},
Title={{A shortest path approach for staff line detection}},
Year={{2007}},
Editor={Delgado, J and Ng, K and Nesi, P and Bellini, P},
Booktitle={{AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS}},
Abstract={{Many music works produced in the past still exist only as original manuscripts or as photocopies. Preserving them entails their digitalization and consequent accessibility in a digital format easy-to-manage. The manual process to carry out this task is very time consuming and error prone. Optical music recognition (OMR) is a form of structured document image analysis where music symbols are isolated and identified so that the music can be conveniently processed. While OMR systems perform well on printed scores, current methods for reading handwritten musical scores by computers remain far from ideal. One of the fundamental stages of this process is the staff line detection. In this paper a new method for the automatic detection of music stave lines based on a shortest path approach is presented. Lines with some curvature, discontinuities, and inclination are robustly detected. The proposed algorithm behaves favourably when compared experimentally with well-established algorithms.}},
Publisher={{IEEE COMPUTER SOC}},
Address10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Pages={{79-85}},
Key={{DOI:10.1109/axmedis.2007.16}}, 
Type={Proceedings Paper},
Note={Citations: crossref, scopus, wos}
}       